# 排序

### 交换

交换变量a,b有以下方法

1. 临时变量  
    > t=a; a=b; b=t;
    > 
    > STL中的std::swap()就是这种方法，这种方法通用且容易理解
2. 基础数据位运算^=  
    > a^=b^=a^=b;
    >
    > 仅限基础数据，并且需要&a != &b，否则第一步之后就变成0了
3. 代数运算法
    > 在高代证明*交换行列式两行行列式不变*时用到过
    > 
    > a+=b; b-=a; b=-b; a-=b;
    >
    > 同样需要&a != &b,否则在第二步就变成0了

以下排序均用std::swap来进行交换。由于升序和降序排序没有本质区别且易相互转换，以下以升序排序为例。

### 3种简单排序

接下来我们介绍3种简单排序，它们的代码量都在10行左右甚至更少（也可能出现在中学的信息课本中）。分别是冒泡排序、选择排序、插入排序

下面以python语法的伪代码描述排序算法，C++实现见osrt.cpp

## 冒泡排序

```python
@loop_n_times # 循环重复n次
def f():
    for i in range(1,n): # 从左到右遍历
        if a[i] < a[i-1]: # 遇到逆序就交换
            swap()
```

冒泡排序过程中，每一趟会交换出最大值到右边，并且沿途也可能会发生交换

最差情况为原本即为逆序排列，这时每一趟相当于仅把最左边的元素“搬运”到最右边，比较次数=$\Theta(n^2)$

## 选择排序

```python
for i in range(0,n):
    
    min_idx = argmin(i,n) # 选定一个最小值
    swap(a[i],a[min_idx]) # 交换到最左边
```

选择排序每次仅在当前无序序列中选择一个最值（最大值/最小值）放到两端（最右边/最左边）

最差情况也为原本即为逆序排列，比较次数=$\Theta(n^2)$

选择排序由于每次仅交换一个最大值，对于其他位置，不改变局部单调性。

选择排序推荐在数据类型$time(Copy) \gt time(Compare)$时使用

## 插入排序

```python
for i in range(1,n):
    # 将a[i]插入到a[0]~a[i-1]中
    pos = lower_bound(0,i,a[i])
    a[0:i] = a[0:i-1].insert(pos,a[i])
```

插入排序每次将有序序列长度扩大1，即对于a[i]，在插入后a[0]-a[i]都是有序的。对于新加入的元素a[i]，小于它的元素不动，大于它的元素右移一格，然后插入a[i]。该过程如同扑克牌插入牌一样因此称为插入排序

最差情况也为原本即为逆序排列，比较次数=$\Theta(n^2)$

插入排序利用了局部有序性，因此可以在子序列比较时提前停止。每次插入时相当于一次改进的冒泡算法，在a[i]左边只有比较没有交换，相比于冒泡排序减少了比较次数。

插入排序在简单数据的实际测试中是3种简单排序算法中相对高效的。

## 简单排序算法的分析

{: .highlight}
> 本节可略过

基于邻位比较算法（冒泡和插入）的最差时间复杂度不会低于$\Theta(n^2)$

将待排序视为一个排列(permutation)，其最大的逆序数为$1+2+3+...+n-1={n^2+n \over 2}$，平均逆序数为${n^2+n \over 4}$。而一次相邻元素的交换只能使逆序数-1，因此平均需要${n^2+n \over 4}=\Theta(n^2)$次比较

### 进一步的排序算法

3种简单排序算法的平均时间复杂度都为$\Theta(n^2)$，接下来我们来探究如何进一步优化排序算法

选择排序在使用堆优化寻找最值后，时间复杂度为$\Theta (nlogn)$  
插入排序在使用了叫做希尔增量的技巧后，时间复杂度可以减少到$O(n^{1.5})$甚至更低，但时间复杂度分析很复杂  
冒泡排序使用了一种分而治之的思想后，平均时间复杂度可以为$\Theta(nlogn)$，但本身时间复杂度$\omicron(n^2)$  
将分而治之的想法贯彻到底，我们得到了归并排序，时间复杂度为$\Theta (nlogn)$

## 堆排序

先看选择排序

```python
for i in range(0,n):
    max_idx = argmax(0,n-i)
    swap(a[n-1-i],a[max_idx])
```

当我们不采用遍历寻找最大值（即argmax），而采用最大堆获得最大值时，就得到了堆排序，下面是一段非原位生成(Out-place)的伪代码

```python
heap = Heap.create(a)
for i in range(0,n):
    max_val = heap.pop()
    a[n-1-i] = max_val
```

由于堆在出堆时，会将最大元素移动到末尾，因此只需要稍微改动下出堆的代码就完成了原位生成(In-place)的堆排序，代码见sort.cpp

由于建堆需要$O(n)$时间，每次调整需要$O(logn)$时间，调整n次，可得堆排序$T(n)=O(nlogn)$。最好情况下省去了建堆时间可得$T(n)= \Omega(nlogn)$。因此堆排序的时间复杂度为$\Theta (nlogn)$


## 希尔排序

```python
increasement = [1,3,7] # ... 
increasement.reverse()
for d in increasement: # 对于从大到小的每一个增量
    for i in range(d): # 按照增量d的间隔进行插入排序
        insert_sort(a[i::d])
```

希尔排序算法的时间复杂度不仅与待排序序列有关，还与增长序列的选取有关，希尔排序的平均复杂度分析极为复杂，希尔排序的最差时间复杂度为$O(n^{1.3})$~$O(n^2)$

Shell增量序列，即希尔排序在1959年刚发明时提出

Hibbard增量序列在1963年提出，其通项为$a_n=2^k -1$，即$1,3,7,15,31,...$，可以证明采用Hibbard增量的希尔排序具有$T(n)=O(n^{3/2})$。根据[wikiwand](https://www.wikiwand.com/en/Shellsort#Gap_sequences)，在实际场景中，希尔排序的平均时间复杂度为$O(n^{5/4})$

此外，根据[wikiwand](https://www.wikiwand.com/en/Shellsort)，具有长度为p的增量序列的希尔排序，对N个元素进行排序时，其平均时间复杂度具有下界：当$p\le log_2N$时，$\Omega(pN^{1+1/p})$；当$p\gt log_2N$时，$\Omega(pN)$。即希尔排序可以达到近似$NlogN$的时间复杂度


## 归并排序

## 快速排序

## 通用排序算法的$nlogn$下界

## 基数排序